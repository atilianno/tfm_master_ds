---
title: "TFM_E2_Grupo02"
output:
  html_document: default
  word_document: default
  pdf_document: default
date: "2023-08-22"
---

# ###############################################################################
# PREPARAR ENTORNO DE TRABAJO
# ###############################################################################

```{r setup, include=FALSE}
library(dplyr)
library(factoextra)
library(ggplot2)
library(cluster)
library(tidyverse)
library(ggcorrplot)
library(writexl)
library(openxlsx)
library(PerformanceAnalytics)
library(corrplot)
library(ggplot2)
library(car)
library(simstudy)
library(data.table)
library(corrr)
library(dbscan)
library(DMwR2)
library(FactoMineR)
library(factoextra)
library(ggthemes)
library(fmsb)
library(SCORPIUS)
library(scatterplot3d)
library(dbscan)
```

# ###############################################################################
# FUNCIONES PROCESAR DATOS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}
################################################################################
# Función para preparar y limpiar DataFrames
################################################################################

limpiar_dataframe <- function(df) {
  
  # Seleccionar columnas de interés
  df <- df[,c("ISO3","PRODUCT_NAME","ENERGY_100G","FAT_100G","CARBOHYDRATES_100G","PROTEINS_100G", "SUGARS_100G", "SALT_100G")]

  # Eliminar registros duplicados
  df <- subset(df, !duplicated(df))

  # Convertir a numérico
  PRODUCT_NAME <- df[,"PRODUCT_NAME"]
  ISO3 <- df[,"ISO3"]

  df_nuevo <- df %>%
    mutate(across(where(is.character), type.convert, as.is = TRUE)) %>%
    select_if(is.numeric)

  df_nuevo <- cbind(ISO3, PRODUCT_NAME, df_nuevo)

  # Eliminar filas con suma de columnas numéricas igual a 0
  suma_columnas <- rowSums(df_nuevo[,3:ncol(df_nuevo)])
  df_nuevo <- cbind(df_nuevo, suma = suma_columnas)
  df_nuevo <- subset(df_nuevo, suma != 0)
  df_nuevo <- df_nuevo[, -which(names(df_nuevo) == "suma")]
  
  # Omitir NA
  df_nuevo <- na.omit(df_nuevo)
  
  # Elimina registros duplicados
  df_nuevo <- subset(df_nuevo, !duplicated(df_nuevo))

  return(df_nuevo)
}
################################################################################
# Local Outlier Factor (LOF)
################################################################################

eliminar_outliers_lof <- function(df, k, threshold) {
  
  lof_scores <- lof(df, k = k)
  df_lof <- cbind(df, lof_score = lof_scores)
  df_clean <- subset(df_lof, lof_score <= threshold)
  return(df_clean)
}

################################################################################
# Función para normalizar DataFrames
################################################################################

escalar_dataframe <- function(df) {
  
  df_nuevo <- df %>%
  mutate(PRODUCT_NAME = as.factor(PRODUCT_NAME))
  
  #df_nuevo <- as.data.frame(scale(df[,-1:-2]))
  df_nuevo <- df_nuevo[,-1:-2] %>%
  mutate_all(~ (.-min(.)) / (max(.) - min(.)))
  
  return(df_nuevo)
}

escalar_dataframe_CUANTIL <- function(df, cuantil) {

  df_nuevo <- df %>% 
    mutate(outlier = ifelse(lof_score > cuantil, 1, 0))

 return(df_nuevo)
}

################################################################################
# Función para PCA
################################################################################

PCA_dataframe <- function(df) {
  
  df_nuevo <- PCA(df, scale.unit = F, ncp = 6, graph = F)
  
  return(df_nuevo)
}

################################################################################
# Función para LOF
################################################################################

LOF_dataframe <- function(df) {
  
  df_nuevo <- lof(df, minPts = 7)
  
  return(df_nuevo)
}

################################################################################
# Función para loft score
################################################################################

LOF_SCORE_dataframe <- function(df_pca, df_lof, df_clean) {
  
  df_nuevo_before <- data.frame(df_pca$ind$coord[,1:3])
  df_nuevo <- cbind(df_nuevo_before, lof_score = df_lof)
  #df_nuevo <- cbind(df_nuevo_before, fraud = df_clean$, lof_score = df_clean$lof)
  
  return(df_nuevo)
}

################################################################################
# Función para obtener cuantiles específicos
################################################################################

obtener_cuantiles <- function(data, porcentaje) {
  
  resultado_quantile <- quantile(data$lof_score, probs = c(0, porcentaje))
  porcentaje_str <- paste0(as.character(porcentaje*100),"%")
    
  # Extraer los cuantiles
  cuantil_0 <- resultado_quantile["0%"]
  cuantil_1 <- resultado_quantile[porcentaje_str]
  
  return(list(cuantil_0 = cuantil_0, cuantil_1 = cuantil_1))
}

################################################################################
# Función para remover outliers
################################################################################

remove_outliers <- function(data, column, sd_threshold = 2) {
  data[abs(scale(data[[column]])) < sd_threshold, ]
}

################################################################################
# Función para Obtener las columnas cuantitativas del dataframe
################################################################################

columnas_cuantitativas <- function(df) {
  
  columnas <- sapply(df, is.numeric)
  
  return(columnas)
}

################################################################################
# Función para Aplicar filtros negativos
################################################################################

# Crear una función que verifica si alguna de las palabras está presente en el texto
verificar_palabras <- function(texto, palabras) {
  sapply(palabras, function(palabra) grepl(palabra, texto))
}

filtro_negativo <- function(df, palabras_a_eliminar) {

  # Identificar las filas que contienen alguna de las palabras a eliminar
  filas_a_eliminar <- apply(df, 1, function(row) any(verificar_palabras(row["PRODUCT_NAME"], palabras_a_eliminar)))
  
  # Eliminar las filas identificadas del dataframe original
  df_nuevo1 <- df[!filas_a_eliminar, ]
  
  #Elimino los faltantes
  df_nuevo1 <- df_nuevo1[complete.cases(df_nuevo1), ]
  
  return(df_nuevo1)
}

```


# ###############################################################################
# FUNCIONES GRÁFICOS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}

################################################################################
# Funcion de gráfico "Distribución LOF Score"
################################################################################

graf_distribucion_LOF <- function(df, producto) {
  
  titulo <- paste0("Distribución LOF Score - ", producto)
  
  distribucion <- ggplot(df, aes(x=Dim.1 ,y=Dim.2)) + 
    geom_point(aes(size=lof_score)) +
  ggtitle(titulo) +
    theme_minimal()

  distribucion
}

################################################################################
# Funcion de gráfico "Distribución LOF Score"
################################################################################}

graf_distribucion_OUTLIERS_LOF <- function(df, producto) {
  
  titulo <- paste0("Distribución LOF Score - [OUTLIERS] ", producto)
  
  lof_visual_lof_score <- ggplot(df, aes(x=Dim.1 ,y=Dim.2, color=outlier)) + 
      geom_point() +
    ggtitle(titulo)+
      theme_minimal()
  
  lof_visual_lof_score
}

################################################################################
# Funcion de gráfico "Distribución LOF Score"
################################################################################

graf_distribucion_densidad_LOF <- function(df, producto) {
  
  titulo <- paste0("Distribución LOF Score [DENSIDAD] - ", producto)
  
  df %>%
  filter(lof_score <= 1.75) %>% 
  ggplot( aes(x=lof_score)) +
    geom_density( color="#e9ecef", fill = "#c90076", alpha=0.7) +
    scale_fill_manual(values="#8fce00") +
    xlab("LOF Score")+
  ggtitle(titulo)+
    theme_minimal() +
    labs(fill="")
}

################################################################################
# Funcion de gráfico "Varianza explicada por cada dimensión"
################################################################################

graf_var_explicada_pca <- function(df, producto) {
  
  titulo <- paste0("Varianza explicada por cada dimensión [PCA] - ", producto)
  
  fviz_eig(df, ncp = 6, addlabels = T, main = titulo)
}

################################################################################
# Función para gráficos "HISTOGRAMAS"
################################################################################

graf_histogramas <- function(df, producto) {
    
  # Obtener las columnas cuantitativas del dataframe
  columnas_cuantitativas <- columnas_cuantitativas(df)
  
  # Crear un histograma para cada columna cuantitativa
  for (columna in names(df[columnas_cuantitativas])) {
    plot <- df[, columna]
    
    p <- ggplot(data.frame(x = plot), aes(x)) +
      geom_histogram(binwidth = 0.5, fill = "steelblue", color = "white") +
      labs(title = paste("Histograma de", columna, producto),
           x = columna,
           y = "Frecuencia")
    
    print(p)
  }
}

################################################################################
# Función para gráficos "DOSPERSIÓN 3D"
################################################################################

dispersion_3d <- function(df1, df2, df3, column1, column2, column3, producto){
  
scatterplot3d(df1, df2, df3,
              xlab = column1, ylab = column2, zlab = column3,
              main = producto)
}
```

# ###############################################################################
# FUNCIONES CLUSTER
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}

colores = c("#00AFBB", "#E7B800", "#FC4E07","#7A378B", "#Ac9E11","#7C7899")

################################################################################
# Funcion de gráfico "Elbow"
################################################################################

graf_cluster_optimos <- function(df) {
  
  elbow <- fviz_nbclust(x = df, FUNcluster = kmeans, method = "wss",
                               k.max = 15, diss = get_dist(df, method = "euclidean"), 
                               nstart = 25)
  print(elbow)
}

################################################################################
# Funcion de CLUSTERING "KMEANS"
################################################################################

clustering_kmeans <- function(df, n_clusters) {
  
  set.seed(123)
  km_clusters <- kmeans(x = df, centers = n_clusters, nstart = 50)
  
  return(km_clusters)
  
}

graf_clustering_kmeans <- function(df, km_clusters, producto) {
  
  titulo <- paste0("Resultados clustering K-means ", producto)
  
  fviz_cluster(object = km_clusters, data = df, show.clust.cent = TRUE,
               ellipse.type = "euclid", star.plot = TRUE, repel = TRUE,
               pointsize = 0.5, outlier.color = "darkred", geom = "point") +
    theme_bw() +
    theme(legend.position = "none") +
    ggtitle(titulo)
}

################################################################################
# Funcion de CLUSTERING "EUCLIDEAN"
################################################################################

clustering_euclidean <- function(df, n_clusters) {
  
  set.seed(101)
  
  hc_euclidea_av <- hclust(d = dist(x = df, method = "euclidean"),
                           method = "average")
  
  return(hc_euclidea_av)
}

graf_clustering_euclidean <- function(df, n_clusters, producto, hc_euclidea_av) {
  
  titulo <- paste0("clustering Jerárquico ", producto)
  subtitulo <- paste0("Distancia euclidea Promedio, k=", n_clusters)
  
  fviz_dend(x = hc_euclidea_av, k = n_clusters, cex = 0.5,
            k_colors = c("red","blue","green","magenta", "brown"),color_labels_by_k = T,
            lwd = 0.2,type = "r",label_cols = rainbow(nrow(df)),
            rect_lty = "lightblue") +
    geom_hline(yintercept = 3.65, linetype = "dashed") +
    labs(title = titulo,
         subtitle = subtitulo)
}

################################################################################
# Funcion de CLUSTERING "KMEANS SUPERPUESTO"
################################################################################

clustering_kmeans_SUPERPUESTO <- function(df, n_clusters, producto) {
  
  titulo <- paste0("Resultados clustering K-means superpuestos - ", producto)
  
  pam.res <- pam(df, n_clusters)
  
  # Visualización
  fviz_cluster(pam.res, geom = "point", ellipse.type = "norm",
               show.clust.cent = TRUE,star.plot = TRUE)+
    labs(title = titulo)+ theme_bw()
}

################################################################################
# Funcion de GRÁFICO "KMEANS Y PCA"
################################################################################

PCA_CLUSTER_KMEANS <- function(df, n_clusters) {

# PCA
pca<- prcomp(df, scale=FALSE)
df.pca <- pca$x

# Cluster over the three first PCA dimensions
kc <- kmeans(df.pca, n_clusters)

fviz_pca_biplot(pca, label="var", habillage=as.factor(kc$cluster)) +
  labs(color=NULL) + ggtitle("") +
  theme(text = element_text(size = 12),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"),
        legend.key = element_rect(fill = "white"))
}

################################################################################
# Funcion para OBTENER CENTROIDES
################################################################################

centroides_clustering <- function(clusters) {
  
  # Obtener los centroides de cada clúster
  centroids <- as.data.frame(clusters$centers)
  
  # Obtener el valor mínimo y máximo en el dataframe
  min_value <- min(centroids, na.rm = TRUE)
  max_value <- max(centroids, na.rm = TRUE)
  
  # Escalar los datos entre 0 y 1
  scaled_df <- (centroids - min_value) / (max_value - min_value)
  
  # Define the variable ranges: maximum and minimum
  max_min <- data.frame(
    ENERGY_100G = c(1, 0), FAT_100G = c(1, 0), CARBOHYDRATES_100G = c(1, 0),PROTEINS_100G = c(1, 0), 
    SUGARS_100G = c(1, 0), SALT_100G = c(1, 0)
  )
  rownames(max_min) <- c("Max", "Min")
  
  # Bind the variable ranges to the data
  df_min_max <- rbind(max_min, scaled_df)
  
  return(df_min_max)
}

################################################################################
# Función para gráficos "radar chart"
################################################################################

create_beautiful_radarchart <- function(data, color = "#00AFBB", 
                                        vlabels = colnames(data), vlcex = 0.7,
                                        caxislabels = NULL, title = NULL, ...){
  radarchart(
    data, axistype = 1,
    
    # Customize the polygon
    pcol = color, pfcol = scales::alpha(color, 0.3), plwd = 2, plty = 1,
    
    # Customize the grid
    cglcol = "grey", cglty = 1, cglwd = 0.8,
    
    # Customize the axis
    axislabcol = "grey", 
    
    # Variable labels
    vlcex = vlcex, vlabels = vlabels,
    caxislabels = caxislabels, title = title, ...
    
  )
}

graf_radarchart <- function(df){
  # Reduce plot margin using par()
  op_full <- par(mar = c(1, 2, 2, 2))
  
  # Create the radar charts
  create_beautiful_radarchart(
    data = df, caxislabels = c(0, .25, .5,.75, 1),
    color = colores
  )
  
  # Add an horizontal legend
  legend(
    x = "bottom", legend = rownames(df[-c(1,2),]), horiz = TRUE,
    bty = "n", pch = 20 , col = colores,
    text.col = "black", cex = 1, pt.cex = 1.5
    )
  par(op_full)
}

graf_radarchart_clusters <- function(df, titles, n_clusters){
  
  # Create the radar chart
  for(i in 1:n_clusters){
    create_beautiful_radarchart(
      data = df[c(1, 2, i+2), ], caxislabels = c(0, .25, .5, .75, 1),
      color = colores[i], title = titles[i],
      width = 5, height = 5, mar = c(0, 0, 0, 0)
    )
  }
}

################################################################################
# Función para 
# "top10 productos más cercanos al centroide que representan cada cluster"
################################################################################

top10_clusters <- function(df, n_clusters){
  
  # Realizar clustering en el dataframe
  set.seed(123)
  df_top <- df
  km_clusters <- kmeans(x = df_top[, c("ENERGY_100G", "FAT_100G", "CARBOHYDRATES_100G", "PROTEINS_100G", "SUGARS_100G", "SALT_100G")], centers = n_clusters, nstart = 50)
  
  # Obtener las asignaciones de clúster
  cluster_assignments <- km_clusters$cluster
  
  # Agregar las asignaciones de clúster al dataframe
  df_top$cluster <- cluster_assignments
  
  # Inicializar una lista para almacenar los productos más cercanos a cada centroide
  closest_products <- vector("list", max(cluster_assignments))
  
  # Encontrar los productos más cercanos a cada centroide
  for (cluster in 1:max(cluster_assignments)) {
    cluster_center <- km_clusters$centers[cluster, ]
    distancedf_normalizado <- apply(df_top[, c("ENERGY_100G", "FAT_100G", "CARBOHYDRATES_100G", "PROTEINS_100G", "SUGARS_100G", "SALT_100G")], 1, function(row) {
      sum((row - cluster_center)^2)
    })
    closest_products[[cluster]] <- head(order(distancedf_normalizado), 10)
  }
  
  # Imprimir los productos más cercanos a cada centroide
  for (cluster in 1:max(cluster_assignments)) {
    cat("Cluster", cluster, ":\n")
    print(df_top[closest_products[[cluster]], c("PRODUCT_NAME", "ENERGY_100G", "FAT_100G", "CARBOHYDRATES_100G", "PROTEINS_100G", "SUGARS_100G", "SALT_100G")])
    cat("\n")
  }
}
```

# ###############################################################################
# ###############################################################################
# CARGA DATOS
# ###############################################################################
# ###############################################################################


```{r, echo = FALSE, warning = FALSE}
################################################################################
# Carga de datos
################################################################################
df_seitan_all_vars <- data.frame(read.csv2('seitan.csv', sep=','))
df_tofu_all_vars <- data.frame(read.csv2('tofu.csv', sep=','))
df_soja_all_vars <- data.frame(read.csv2('soja.csv', sep=','))

################################################################################
# Limpiar Dataframe
################################################################################

df_seitan <- limpiar_dataframe(df_seitan_all_vars)
seitan_clean <- escalar_dataframe(df_seitan)

df_tofu <- limpiar_dataframe(df_tofu_all_vars)
tofu_clean <- escalar_dataframe(df_tofu)

df_soja <- limpiar_dataframe(df_soja_all_vars)
soja_clean <- escalar_dataframe(df_soja)


# Crear un vector con las palabras a buscar

palabras_a_eliminar <- c("SALSA DE SOJA","SAUCE SOJA", "SAUCE SOJA","BEBIDA DE SOJA", "YAOURT SOJA","YOGURT DE SOJA","CHOCOLAT","ARROZ Y SOJA","LECHE","MOUSSE","MILK","ACEITE","DESSERT","PAN SOJA","BOISSON SOJA","GLACE","ML","SAUCE DE SOJA","SAUCE","SALSA","BIBEDA DE SOJA","LAIT SOJA","VIVESOY SOJA","LAIT DE SOJA","YAOURT","POSTRE","MUESLI","YOGUR","BEBIDA","MARGARINA","VINAIGRETTE","DRINK","SAUCE","BATIDO","LAIT","MAYONNAISE","CAFE","VANILLE","NATA","YOGURT","LACTOVISOY","ALIMENTO DE SOYA","ALIMENTO LIQUIDO DE SOYA","BEVANDA","SWEET SOY","VANILLE","VANILLA","UNSWEETENED","SWEETENED","STRAWBERRY","PROTEIN ISOLATE","SOYA CALCIUM","BLUEBERRY","BEVERAGE","BARISTA","SOYA A TARTINER","JUGO","PROTEIN POWDER","PROTEIN ISOLATE","CACAO","CALCIUM","CALCIO","NUTRI SOJA","SOIA BIANCO CREMOSO","LECITINA","LECITHINE","LATTE","HARICOTS","GERME","GELATO","GATEAU","FROMAGE FRAIS","INFUSION","SOYBEAN PASTE","MIXBEANS","MISO SOUP","SOYBEANS","PATE DE SOJA","PLAINSOYA","PETIT’SOIF","SOYBEANS","FRAMBOISE","MANGO","DOUCEUR","SOJABOHNENKEIMLINGE","KEIMLINGE","MANGUE","PECHE","MANZANA","VICHYSSOISE","CHOCOAVENA","AVENA","MANI","SEMILLAS","PAN RALLADO","GARBANZOS","RAGU","CHILI")

df_seitan <- filtro_negativo(df_seitan, palabras_a_eliminar)
df_tofu <- filtro_negativo(df_tofu, palabras_a_eliminar)
df_soja <- filtro_negativo(df_soja, palabras_a_eliminar)

df_seitan <- na.omit(df_seitan)
df_tofu <- na.omit(df_tofu)
df_soja <- na.omit(df_soja)
```


# ###############################################################################
# ###############################################################################
# SEITAN
# ###############################################################################
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}
# LOF
seitan_lof <- LOF_dataframe(seitan_clean)

# PCA
seitan_pca <- PCA_dataframe(seitan_clean)

# LOFT SCORE
seitan_lof_score <- LOF_SCORE_dataframe(seitan_pca, seitan_lof, seitan_clean)

# corte quantil
seitan_probabilidad <- 0.9

# quantiles
seitan_quantiles_vars <- obtener_cuantiles(seitan_lof_score, seitan_probabilidad)

# Ahora 'quantiles_vars' es una lista con los cuantiles
seitan_cuantil_1 <- seitan_quantiles_vars$cuantil_0
seitan_cuantil_2 <- seitan_quantiles_vars$cuantil_1

# DATAFRAMES outliers

df_seitan <- df_seitan[seitan_lof < seitan_cuantil_2,]
df_seitan_outliers <- df_seitan[seitan_lof >= seitan_cuantil_2,]

# Escalar DATAFRAME - Cuantil
seitan_lof_score <- escalar_dataframe_CUANTIL(seitan_lof_score, seitan_cuantil_2)

# Eliminar valores atipicos univariantes
columns_to_check_seitan <- 3:ncol(df_seitan)
for (column_seitan in columns_to_check_seitan) {
  df_seitan <- remove_outliers(df_seitan, column_seitan)
}

# Omitir NA
df_seitan <- na.omit(df_seitan)
```

# ###############################################################################
# ANÁLISIS DATOS
# ###############################################################################
              

```{r, echo = FALSE, warning = FALSE}

graf_var_explicada_pca(seitan_pca, "seitan")

```

```{r, echo = FALSE, warning = FALSE}

graf_distribucion_LOF(seitan_lof_score, "seitan")
```


```{r, echo = FALSE, warning = FALSE}

graf_distribucion_densidad_LOF(seitan_lof_score, "seitan")
```


```{r, echo = FALSE, warning = FALSE}

graf_distribucion_OUTLIERS_LOF(seitan_lof_score, "seitan")
```

```{r, echo = FALSE, warning = FALSE}
graf_histogramas(df_seitan, "- seitan")
```

```{r, echo = FALSE, warning = FALSE}
#Datos normalizados para el seitan
df_seitan_normalizado <- escalar_dataframe(df_seitan)
```


```{r, echo = FALSE, warning = FALSE}
graf_histogramas(df_seitan_normalizado, "- seitan [NORMALIZADO]")
```

```{r, echo = FALSE, warning = FALSE}

# Crear el gráfico de dispersión en 3D

dispersion_3d(df_seitan_normalizado$PROTEINS_100G, df_seitan_normalizado$FAT_100G, df_seitan_normalizado$CARBOHYDRATES_100G, "PROTEINS_100G", "FAT_100G", "CARBOHYDRATES_100G", "seitan")

dispersion_3d(df_seitan_normalizado$SALT_100G, df_seitan_normalizado$ENERGY_100G, df_seitan_normalizado$SUGARS_100G, "SALT_100G", "ENERGY_100G", "SUGARS_100G", "seitan")
```

```{r, echo = FALSE, warning = FALSE}

# Exportar el DataFrame a un archivo CSV
write.csv(df_seitan, "seitan_final.csv", row.names = FALSE)
```

# ###############################################################################
# CLUSTERS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}
# total de cluster óptimos
graf_cluster_optimos(df_seitan_normalizado)
```


```{r, echo = FALSE, warning = FALSE}
# Número de clusters
n_clusters_seitan <- 3

seitan_kms_clusters <- clustering_kmeans(df_seitan_normalizado, n_clusters_seitan)
graf_clustering_kmeans(df_seitan_normalizado, seitan_kms_clusters, "seitan")
```

```{r, echo = FALSE, warning = FALSE}
seitan_euclidean_clusters <- clustering_euclidean(df_seitan_normalizado, n_clusters_seitan)
graf_clustering_euclidean(df_seitan_normalizado, n_clusters_seitan, "seitan", seitan_euclidean_clusters)
```

```{r, echo = FALSE, warning = FALSE}
clustering_kmeans_SUPERPUESTO(df_seitan_normalizado, n_clusters_seitan, "seitan")
```

```{r, echo = FALSE, warning = FALSE}
# Biplot PCA y K-Means para medir representatividad
PCA_CLUSTER_KMEANS(df_seitan_normalizado, n_clusters_seitan)
```

```{r, echo = FALSE, warning = FALSE}
df_seitan_min_max <- centroides_clustering(seitan_kms_clusters)
df_seitan_min_max
```

```{r, echo = FALSE, warning = FALSE}
# Identificar filas con índices que contienen "Max" o "Min"
indices_a_eliminar_seitan_cluster <- grep("Max|Min", rownames(df_seitan_min_max))

# Eliminar esas filas
df_centroides_seitan <- df_seitan_min_max[-indices_a_eliminar_seitan_cluster, ]

# Verificar el DataFrame resultante
print(df_centroides_seitan)

# Exportar el DataFrame a un archivo CSV
write.csv(df_centroides_seitan, "seitan_centroides.csv", row.names = FALSE)
```



```{r, echo = FALSE, warning = FALSE}
graf_radarchart(df_seitan_min_max)
```

```{r, echo = FALSE, warning = FALSE}
graf_radarchart_clusters(df_seitan_min_max, c("1", "2", "3"), n_clusters_seitan)
```

```{r, echo = FALSE, warning = FALSE}
# Visualizar los productos más cercanos al centroide que representan cada cluster top10
top10_clusters(df_seitan, n_clusters_seitan)
```

# ###############################################################################
# ###############################################################################
# TOFU
# ###############################################################################
# ###############################################################################


```{r, echo = FALSE, warning = FALSE}

# LOF
tofu_lof <- LOF_dataframe(tofu_clean)

# PCA
tofu_pca <- PCA_dataframe(tofu_clean)

# LOFT SCORE
tofu_lof_score <- LOF_SCORE_dataframe(tofu_pca, tofu_lof, tofu_clean)

# corte quantil
tofu_probabilidad <- 0.9

# quantiles
tofu_quantiles_vars <- obtener_cuantiles(tofu_lof_score, tofu_probabilidad)

# Ahora 'quantiles_vars' es una lista con los cuantiles
tofu_cuantil_1 <- tofu_quantiles_vars$cuantil_0
tofu_cuantil_2 <- tofu_quantiles_vars$cuantil_1

# DATAFRAMES outliers

df_tofu <- df_tofu[tofu_lof < tofu_cuantil_2,]
df_tofu_outliers <- df_tofu[tofu_lof >= tofu_cuantil_2,]

# Escalar DATAFRAME - Cuantil
tofu_lof_score <- escalar_dataframe_CUANTIL(tofu_lof_score, tofu_cuantil_2)

# Eliminar valores atipicos univariantes

columns_to_check_tofu <- 3:ncol(df_tofu)

for (column_tofu in columns_to_check_tofu) {
  df_tofu <- remove_outliers(df_tofu, column_tofu)
}

# Omitir NA
df_tofu <- na.omit(df_tofu)
```

# ###############################################################################
# ANÁLISIS DATOS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}

graf_var_explicada_pca(tofu_pca, "tofu")

```

```{r, echo = FALSE, warning = FALSE}

graf_distribucion_LOF(tofu_lof_score, "tofu")
```


```{r, echo = FALSE, warning = FALSE}

graf_distribucion_densidad_LOF(tofu_lof_score, "tofu")
```


```{r, echo = FALSE, warning = FALSE}

graf_distribucion_OUTLIERS_LOF(tofu_lof_score, "tofu")
```


```{r, echo = FALSE, warning = FALSE}
graf_histogramas(df_tofu, "- tofu")
```

```{r, echo = FALSE, warning = FALSE}
#Datos normalizados para el tofu
df_tofu_normalizado <- escalar_dataframe(df_tofu)

graf_histogramas(df_tofu_normalizado, "- tofu [NORMALIZADO]")
```

```{r, echo = FALSE, warning = FALSE}

# Crear el gráfico de dispersión en 3D

dispersion_3d(df_tofu_normalizado$PROTEINS_100G, df_tofu_normalizado$FAT_100G, df_tofu_normalizado$CARBOHYDRATES_100G, "PROTEINS_100G", "FAT_100G", "CARBOHYDRATES_100G", "tofu")

dispersion_3d(df_tofu_normalizado$SALT_100G, df_tofu_normalizado$ENERGY_100G, df_tofu_normalizado$SUGARS_100G, "SALT_100G", "ENERGY_100G", "SUGARS_100G", "tofu")
```

```{r, echo = FALSE, warning = FALSE}

# Exportar el DataFrame a un archivo CSV
write.csv(df_tofu, "tofu_final.csv", row.names = FALSE)
```

# ###############################################################################
# CLUSTERS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}
# total de cluster óptimos
graf_cluster_optimos(df_tofu_normalizado)
```


```{r, echo = FALSE, warning = FALSE}
# Número de clusters
n_clusters_tofu <- 3

tofu_kms_clusters <- clustering_kmeans(df_tofu_normalizado, n_clusters_tofu)
graf_clustering_kmeans(df_tofu_normalizado, tofu_kms_clusters, "tofu")
```

```{r, echo = FALSE, warning = FALSE}
tofu_euclidean_clusters <- clustering_euclidean(df_tofu_normalizado, n_clusters_tofu)
graf_clustering_euclidean(df_tofu_normalizado, n_clusters_tofu, "tofu", tofu_euclidean_clusters)
```

```{r, echo = FALSE, warning = FALSE}
clustering_kmeans_SUPERPUESTO(df_tofu_normalizado, n_clusters_tofu, "tofu")
```

```{r, echo = FALSE, warning = FALSE}
# Biplot PCA y K-Means para medir representatividad
PCA_CLUSTER_KMEANS(df_tofu_normalizado, n_clusters_tofu)
```

```{r, echo = FALSE, warning = FALSE}
df_tofu_min_max <- centroides_clustering(tofu_kms_clusters)
df_tofu_min_max
```

```{r, echo = FALSE, warning = FALSE}
# Identificar filas con índices que contienen "Max" o "Min"
indices_a_eliminar_tofu_cluster <- grep("Max|Min", rownames(df_tofu_min_max))

# Eliminar esas filas
df_centroides_tofu <- df_tofu_min_max[-indices_a_eliminar_tofu_cluster, ]

# Verificar el DataFrame resultante
print(df_centroides_tofu)

# Exportar el DataFrame a un archivo CSV
write.csv(df_centroides_tofu, "tofu_centroides.csv", row.names = FALSE)
```


```{r, echo = FALSE, warning = FALSE}
graf_radarchart(df_tofu_min_max)
```

```{r, echo = FALSE, warning = FALSE}
graf_radarchart_clusters(df_tofu_min_max, c("1", "2", "3"), n_clusters_tofu)
```

```{r, echo = FALSE, warning = FALSE}
# Visualizar los productos más cercanos al centroide que representan cada cluster top10
top10_clusters(df_tofu, n_clusters_tofu)
```

# ###############################################################################
# ###############################################################################
# SOJA
# ###############################################################################
# ###############################################################################


```{r, echo = FALSE, warning = FALSE}

# LOF
soja_lof <- LOF_dataframe(soja_clean)

# PCA
soja_pca <- PCA_dataframe(soja_clean)

# LOFT SCORE
soja_lof_score <- LOF_SCORE_dataframe(soja_pca, soja_lof, soja_clean)

# corte quantil
soja_probabilidad <- 0.9

# quantiles
soja_quantiles_vars <- obtener_cuantiles(soja_lof_score, soja_probabilidad)

# Ahora 'quantiles_vars' es una lista con los cuantiles
soja_cuantil_1 <- soja_quantiles_vars$cuantil_0
soja_cuantil_2 <- soja_quantiles_vars$cuantil_1

# DATAFRAMES outliers

df_soja <- df_soja[soja_lof < soja_cuantil_2,]
df_soja_outliers <- df_soja[soja_lof >= soja_cuantil_2,]

# Escalar DATAFRAME - Cuantil
soja_lof_score <- escalar_dataframe_CUANTIL(soja_lof_score, soja_cuantil_2)

# Eliminar valores atipicos univariantes

columns_to_check_soja <- 3:ncol(df_soja)

for (column_soja in columns_to_check_soja) {
  df_soja <- remove_outliers(df_soja, column_soja)
}

# Omitir NA
df_soja <- na.omit(df_soja)
```

# ###############################################################################
# ANÁLISIS DATOS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}

graf_var_explicada_pca(soja_pca, "soja")

```

```{r, echo = FALSE, warning = FALSE}

graf_distribucion_LOF(soja_lof_score, "soja")
```


```{r, echo = FALSE, warning = FALSE}

graf_distribucion_densidad_LOF(soja_lof_score, "soja")
```


```{r, echo = FALSE, warning = FALSE}

graf_distribucion_OUTLIERS_LOF(soja_lof_score, "soja")
```


```{r, echo = FALSE, warning = FALSE}
graf_histogramas(df_soja, "- soja")
```

```{r, echo = FALSE, warning = FALSE}
#Datos normalizados para el soja
df_soja_normalizado <- escalar_dataframe(df_soja)

graf_histogramas(df_soja_normalizado, "- soja [NORMALIZADO]")
```

```{r, echo = FALSE, warning = FALSE}

# Crear el gráfico de dispersión en 3D

dispersion_3d(df_soja_normalizado$PROTEINS_100G, df_soja_normalizado$FAT_100G, df_soja_normalizado$CARBOHYDRATES_100G, "PROTEINS_100G", "FAT_100G", "CARBOHYDRATES_100G", "soja")

dispersion_3d(df_soja_normalizado$SALT_100G, df_soja_normalizado$ENERGY_100G, df_soja_normalizado$SUGARS_100G, "SALT_100G", "ENERGY_100G", "SUGARS_100G", "soja")
```

```{r, echo = FALSE, warning = FALSE}

# Exportar el DataFrame a un archivo CSV
write.csv(df_soja, "soja_final.csv", row.names = FALSE)
```

# ###############################################################################
# CLUSTERS
# ###############################################################################

```{r, echo = FALSE, warning = FALSE}
# total de cluster óptimos
graf_cluster_optimos(df_soja_normalizado)
```


```{r, echo = FALSE, warning = FALSE}
# Número de clusters
n_clusters_soja <- 3

soja_kms_clusters <- clustering_kmeans(df_soja_normalizado, n_clusters_soja)
graf_clustering_kmeans(df_soja_normalizado, soja_kms_clusters, "soja")
```

```{r, echo = FALSE, warning = FALSE}
soja_euclidean_clusters <- clustering_euclidean(df_soja_normalizado, n_clusters_soja)
graf_clustering_euclidean(df_soja_normalizado, n_clusters_soja, "soja", soja_euclidean_clusters)
```

```{r, echo = FALSE, warning = FALSE}
clustering_kmeans_SUPERPUESTO(df_soja_normalizado, n_clusters_soja, "soja")
```

```{r, echo = FALSE, warning = FALSE}
# Biplot PCA y K-Means para medir representatividad
PCA_CLUSTER_KMEANS(df_soja_normalizado, n_clusters_soja)
```

```{r, echo = FALSE, warning = FALSE}
df_soja_min_max <- centroides_clustering(soja_kms_clusters)
df_soja_min_max
```

```{r, echo = FALSE, warning = FALSE}
# Identificar filas con índices que contienen "Max" o "Min"
indices_a_eliminar_soja_cluster <- grep("Max|Min", rownames(df_soja_min_max))

# Eliminar esas filas
df_centroides_soja <- df_soja_min_max[-indices_a_eliminar_soja_cluster, ]

# Verificar el DataFrame resultante
print(df_centroides_soja)

# Exportar el DataFrame a un archivo CSV
write.csv(df_centroides_soja, "soja_centroides.csv", row.names = FALSE)
```


```{r, echo = FALSE, warning = FALSE}
graf_radarchart(df_soja_min_max)
```

```{r, echo = FALSE, warning = FALSE}
graf_radarchart_clusters(df_soja_min_max, c("1", "2", "3"), n_clusters_soja)
```

```{r, echo = FALSE, warning = FALSE}
# Visualizar los productos más cercanos al centroide que representan cada cluster top10
top10_clusters(df_soja, n_clusters_soja)
```

